name: deploy

on:
  pull_request:
    branches: [ env/dev, env/staging, env/prod ]
    paths:
      - 'infra/envs/**'
      - 'modules/**'
      - '.github/workflows/deploy.yaml'
  push:
    branches: [ env/dev, env/staging, env/prod ]
    paths:
      - 'infra/envs/**'
      - 'modules/**'
      - '.github/workflows/deploy.yaml'
  workflow_dispatch:
    inputs:
      environment:
        description: "Environment to deploy"
        type: choice
        options:
          - dev
          - staging
          - prod
        required: true
        default: dev
      action:
        description: "Action to perform"
        type: choice
        options:
          - plan
          - apply
        required: true
        default: plan

permissions:
  id-token: write
  contents: read
  issues: write
  pull-requests: write

env:
  TF_IN_AUTOMATION: "true"
  TF_INPUT: "false"
  TF_VERSION: "1.6.6"
  AWS_REGION: ${{ vars.TF_BACKEND_REGION }}

jobs:
  plan:
    if: github.event_name == 'pull_request' || (github.event_name == 'workflow_dispatch' && inputs.action == 'plan')
    runs-on: ubuntu-latest
    environment: ${{ github.event_name == 'workflow_dispatch' && inputs.environment || (github.base_ref == 'env/dev' && 'dev' || github.base_ref == 'env/staging' && 'staging' || github.base_ref == 'env/prod' && 'prod' || '') }}
    defaults:
      run:
        shell: bash
    outputs:
      environment: ${{ steps.env.outputs.environment }}
      cluster_name: ${{ steps.env.outputs.cluster_name }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Configure AWS Credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Determine Environment
        id: env
        run: |
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            ENV="${{ inputs.environment }}"
          else
            case "${GITHUB_BASE_REF}" in
              env/dev) ENV="dev" ;;
              env/staging) ENV="staging" ;;
              env/prod) ENV="prod" ;;
              *) ENV="dev" ;;
            esac
          fi
          echo "environment=${ENV}" >> $GITHUB_OUTPUT
          echo "cluster_name=one-click-${ENV}-eks" >> $GITHUB_OUTPUT

      # Infrastructure Plan
      - name: Infrastructure - Terraform Init
        working-directory: infra/envs
        run: |
          terraform init \
            -backend-config="bucket=${{ vars.TF_BACKEND_BUCKET }}" \
            -backend-config="key=global/terraform.tfstate" \
            -backend-config="region=${{ vars.TF_BACKEND_REGION }}" \
            -backend-config="encrypt=true" \
            -backend-config="dynamodb_table=${{ vars.TF_BACKEND_DDB_TABLE }}" \
            -backend-config="kms_key_id=${{ vars.TF_BACKEND_KMS_KEY_ID }}" \
            -backend-config="acl=private" \
            -backend-config="workspace_key_prefix=envs"

      - name: Infrastructure - Terraform Fmt Check
        working-directory: infra/envs
        run: terraform fmt -check -recursive

      - name: Infrastructure - Terraform Validate
        working-directory: infra/envs
        run: terraform validate

      - name: Infrastructure - Select Workspace
        working-directory: infra/envs
        run: |
          ENV="${{ steps.env.outputs.environment }}"
          terraform workspace list | grep -q " $ENV$" || terraform workspace new "$ENV"
          terraform workspace select "$ENV"

      - name: Infrastructure - Terraform Plan
        id: infra_plan
        working-directory: infra/envs
        run: |
          ENV="${{ steps.env.outputs.environment }}"
          VARS="${ENV}/terraform.tfvars"
          terraform plan -var-file="$VARS" -var "region=${AWS_REGION}" -var "aws_profile=" -out=tfplan-infra

      - name: Comment Plan Results on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const comment = `## ðŸš€ Unified Deployment Plan - ${{ steps.env.outputs.environment }}
            
            **Environment:** \`${{ steps.env.outputs.environment }}\`
            **Cluster:** \`${{ steps.env.outputs.cluster_name }}\`
            **Triggered by:** ${context.actor}
            
            ### âœ… Infrastructure Plan
            Infrastructure plan completed successfully!
            
            <details>
            <summary>ðŸ“‹ Infrastructure Plan Details</summary>
            
            - Working Directory: \`infra/envs\`
            - Terraform Workspace: \`${{ steps.env.outputs.environment }}\`
            - Variables File: \`${{ steps.env.outputs.environment }}/terraform.tfvars\`
            - AWS Region: \`${{ env.AWS_REGION }}\`
            - Terraform Version: \`${{ env.TF_VERSION }}\`
            
            </details>
            
            ### ðŸ”„ Applications Plan
            Applications will be planned after infrastructure deployment completes.
            
            **Merge this PR to apply both infrastructure and applications changes.**`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

  deploy:
    if: github.event_name == 'push' || (github.event_name == 'workflow_dispatch' && inputs.action == 'apply')
    runs-on: ubuntu-latest
    environment: ${{ github.event_name == 'workflow_dispatch' && inputs.environment || (github.ref_name == 'env/dev' && 'dev' || github.ref_name == 'env/staging' && 'staging' || github.ref_name == 'env/prod' && 'prod' || '') }}
    concurrency:
      group: ${{ github.workflow }}-${{ github.ref }}
      cancel-in-progress: true
    defaults:
      run:
        shell: bash
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Configure AWS Credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Determine Environment
        id: env
        run: |
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            ENV="${{ inputs.environment }}"
          else
            case "${GITHUB_REF_NAME}" in
              env/dev) ENV="dev" ;;
              env/staging) ENV="staging" ;;
              env/prod) ENV="prod" ;;
            esac
          fi
          echo "environment=${ENV}" >> $GITHUB_OUTPUT
          echo "cluster_name=one-click-${ENV}-eks" >> $GITHUB_OUTPUT

      - name: Wait for manual approval before production
        if: (github.ref_name == 'env/prod') || (github.event_name == 'workflow_dispatch' && inputs.environment == 'prod')
        uses: trstringer/manual-approval@v1
        with:
          secret: ${{ secrets.GITHUB_TOKEN }}
          approvers: rnato35
          minimum-approvals: 1
          issue-title: "Manual approval required for production deployment"
          issue-body: "Please approve this production deployment (infrastructure + applications)."
          exclude-workflow-initiator-as-approver: false

      # ===== INFRASTRUCTURE DEPLOYMENT =====
      - name: Infrastructure - Terraform Init
        working-directory: infra/envs
        run: |
          terraform init \
            -backend-config="bucket=${{ vars.TF_BACKEND_BUCKET }}" \
            -backend-config="key=global/terraform.tfstate" \
            -backend-config="region=${{ vars.TF_BACKEND_REGION }}" \
            -backend-config="encrypt=true" \
            -backend-config="dynamodb_table=${{ vars.TF_BACKEND_DDB_TABLE }}" \
            -backend-config="kms_key_id=${{ vars.TF_BACKEND_KMS_KEY_ID }}" \
            -backend-config="acl=private" \
            -backend-config="workspace_key_prefix=envs"

      - name: Infrastructure - Terraform Fmt Check
        working-directory: infra/envs
        run: terraform fmt -check -recursive

      - name: Infrastructure - Terraform Validate
        working-directory: infra/envs
        run: terraform validate

      - name: Infrastructure - Select Workspace
        working-directory: infra/envs
        run: |
          ENV="${{ steps.env.outputs.environment }}"
          terraform workspace list | grep -q " $ENV$" || terraform workspace new "$ENV"
          terraform workspace select "$ENV"

      - name: Infrastructure - Terraform Plan
        working-directory: infra/envs
        run: |
          ENV="${{ steps.env.outputs.environment }}"
          VARS="${ENV}/terraform.tfvars"
          terraform plan -var-file="$VARS" -var "region=${AWS_REGION}" -var "aws_profile=" -out=tfplan-infra

      - name: Infrastructure - Terraform Apply
        working-directory: infra/envs
        run: terraform apply -auto-approve tfplan-infra

      - name: Wait for EKS Cluster to be Active
        run: |
          echo "Waiting for EKS cluster ${{ steps.env.outputs.cluster_name }} to be available..."
          aws eks wait cluster-active --name ${{ steps.env.outputs.cluster_name }} --region ${{ env.AWS_REGION }}
          echo "EKS cluster is active and ready for applications deployment"

      # ===== APPLICATIONS DEPLOYMENT =====
      - name: Applications - Configure kubectl
        run: |
          aws eks update-kubeconfig --name ${{ steps.env.outputs.cluster_name }} --region ${{ env.AWS_REGION }}
          echo "Kubectl configured for cluster ${{ steps.env.outputs.cluster_name }}"

      - name: Applications - Deploy via Terraform
        working-directory: infra/envs
        run: |
          ENV="${{ steps.env.outputs.environment }}"
          VARS="${ENV}/terraform.tfvars"
          # Re-run plan and apply to ensure applications module is deployed
          terraform plan -var-file="$VARS" -var "region=${AWS_REGION}" -var "aws_profile=" -out=tfplan-apps
          terraform apply -auto-approve tfplan-apps

      - name: Verify Deployment Status
        run: |
          echo "=== ðŸš€ Unified Deployment Summary ==="
          echo "Environment: ${{ steps.env.outputs.environment }}"
          echo "Cluster: ${{ steps.env.outputs.cluster_name }}"
          echo "Region: ${{ env.AWS_REGION }}"
          echo ""
          
          echo "=== Infrastructure Status ==="
          echo "âœ… VPC, EKS Cluster, and Load Balancer Controller deployed"
          
          echo "=== Kubernetes Cluster Status ==="
          kubectl get nodes
          
          echo "=== Namespace Status ==="
          kubectl get namespaces
          
          echo "=== Applications Status ==="
          kubectl get all -n apps || echo "Apps namespace resources are being created..."
          
          echo "=== Ingress Status ==="
          kubectl get ingress -n apps || echo "Ingress resources are being created..."
          
          echo "=== Helm Releases ==="
          helm list -A || echo "No Helm releases found"

      - name: Get Load Balancer URL
        id: lb_url
        continue-on-error: true
        run: |
          echo "Waiting for Load Balancer to be ready..."
          sleep 30
          LB_HOSTNAME=$(kubectl get ingress -n apps nginx-sample -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "pending")
          echo "lb_hostname=${LB_HOSTNAME}" >> $GITHUB_OUTPUT
          echo "Load Balancer: ${LB_HOSTNAME}"

      - name: Create Deployment Summary
        if: always()
        run: |
          echo "## ðŸš€ Unified Deployment Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Environment:** ${{ steps.env.outputs.environment }}" >> $GITHUB_STEP_SUMMARY
          echo "**Cluster:** ${{ steps.env.outputs.cluster_name }}" >> $GITHUB_STEP_SUMMARY
          echo "**Region:** ${{ env.AWS_REGION }}" >> $GITHUB_STEP_SUMMARY
          echo "**Status:** ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ—ï¸ Infrastructure Deployed" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… VPC with public/private subnets across 2 AZs" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… EKS cluster with Fargate profiles" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… AWS Load Balancer Controller" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Security groups and IAM roles" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸš€ Applications Deployed" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… nginx-sample application" >> $GITHUB_STEP_SUMMARY
          if [ "${{ steps.lb_url.outputs.lb_hostname }}" != "pending" ] && [ "${{ steps.lb_url.outputs.lb_hostname }}" != "" ]; then
            echo "- âœ… Load Balancer: \`${{ steps.lb_url.outputs.lb_hostname }}\`" >> $GITHUB_STEP_SUMMARY
            echo "- ðŸŒ Website: http://${{ steps.lb_url.outputs.lb_hostname }}/architecture" >> $GITHUB_STEP_SUMMARY
            echo "- ðŸ’š Health Check: http://${{ steps.lb_url.outputs.lb_hostname }}/health" >> $GITHUB_STEP_SUMMARY
          else
            echo "- â³ Load Balancer: Setting up (check AWS Console)" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“Š Next Steps" >> $GITHUB_STEP_SUMMARY
          echo "1. **Configure kubectl:** \`aws eks update-kubeconfig --name ${{ steps.env.outputs.cluster_name }} --region ${{ env.AWS_REGION }}\`" >> $GITHUB_STEP_SUMMARY
          echo "2. **Check applications:** \`kubectl get all -n apps\`" >> $GITHUB_STEP_SUMMARY
          echo "3. **View ingress:** \`kubectl get ingress -n apps\`" >> $GITHUB_STEP_SUMMARY
          echo "4. **Port forward (if no public ALB):** \`kubectl port-forward -n apps service/nginx-sample 8080:80\`" >> $GITHUB_STEP_SUMMARY